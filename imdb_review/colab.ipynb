{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "anntestGPU.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IH3cpyzl7Q_",
        "colab_type": "code",
        "outputId": "f4cd4dc5-d494-4f4b-f474-6b264a307124",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9rI_dzASyC8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# importing imdb reveiw data of the tf\n",
        "import tensorflow_datasets as tfds\n",
        "imdb, info = tfds.load(\"imdb_reviews\", with_info=True, as_supervised=True)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "train_data, test_data = imdb['train'], imdb['test']\n",
        "\n",
        "training_sentences = []\n",
        "training_labels = []\n",
        "\n",
        "testing_sentences = []\n",
        "testing_labels = []\n",
        "\n",
        "# train_data and test_data are the Token and there values can be get by l.numpy()\n",
        "for s, l in train_data:\n",
        "\ttraining_sentences.append(str(s.numpy()))\n",
        "\ttraining_labels.append(l.numpy())\n",
        "\n",
        "for s, l in test_data:\n",
        "\ttesting_sentences.append(str(s.numpy()))\n",
        "\ttesting_labels.append(l.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3DT4AH5PtEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# converting them to numpy array for having ml fun with them\n",
        "training_labels_final = np.array(training_labels)\n",
        "testing_labels_final = np.array(testing_labels)\n",
        "\n",
        "vocab_size = 10000\n",
        "embedding_dim = 16\n",
        "max_length = 120\n",
        "trunc_type = 'post'\n",
        "oov_tok = \"<OOV>\"\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPcydLTPQZff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fitting on the training sentences\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "word_index = tokenizer.word_index\n",
        "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded = pad_sequences(sequences, maxlen=max_length, truncating=trunc_type)\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "testing_padded = pad_sequences(sequences, maxlen=max_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndMmW46DQuzP",
        "colab_type": "code",
        "outputId": "fa2a292e-5cda-47e0-da17-a709d70078dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "def decode_review(text):\n",
        "\treturn ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
        "\n",
        "print(decode_review(padded[1]))\n",
        "print(training_sentences[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "? ? ? ? ? ? ? b'i have been known to fall asleep during films but this is usually due to a combination of things including really tired being warm and comfortable on the <OOV> and having just eaten a lot however on this occasion i fell asleep because the film was rubbish the plot development was constant constantly slow and boring things seemed to happen but with no explanation of what was causing them or why i admit i may have missed part of the film but i watched the majority of it and everything just seemed to happen of its own <OOV> without any real concern for anything else i cant recommend this film at all '\n",
            "b'I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However on this occasion I fell asleep because the film was rubbish. The plot development was constant. Constantly slow and boring. Things seemed to happen, but with no explanation of what was causing them or why. I admit, I may have missed part of the film, but i watched the majority of it and everything just seemed to happen of its own accord without any real concern for anything else. I cant recommend this film at all.'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHx7Lc8mRFXH",
        "colab_type": "code",
        "outputId": "12a437dc-fd47-4739-ec40-26aa4e360de2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "\ttf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "\ttf.keras.layers.Flatten(),\n",
        "\ttf.keras.layers.Dense(6, activation=\"relu\"),\n",
        "\ttf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 120, 16)           160000    \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1920)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6)                 11526     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 7         \n",
            "=================================================================\n",
            "Total params: 171,533\n",
            "Trainable params: 171,533\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jj0aLYPRs5t",
        "colab_type": "code",
        "outputId": "4c7e6033-dc29-4211-90d9-d707b4439402",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "num_epochs = 10\n",
        "model.fit(padded, training_labels_final, epochs=num_epochs, validation_data=(testing_padded, testing_labels_final))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.4968 - accuracy: 0.7427 - val_loss: 1.2783 - val_accuracy: 0.4973\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.2440 - accuracy: 0.9036 - val_loss: 1.6094 - val_accuracy: 0.4982\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.1000 - accuracy: 0.9731 - val_loss: 2.1294 - val_accuracy: 0.4956\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0285 - accuracy: 0.9965 - val_loss: 2.6696 - val_accuracy: 0.4971\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0119 - accuracy: 0.9985 - val_loss: 3.0414 - val_accuracy: 0.4980\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0071 - accuracy: 0.9990 - val_loss: 3.2785 - val_accuracy: 0.4989\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0026 - accuracy: 0.9997 - val_loss: 3.6260 - val_accuracy: 0.4971\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 7.6209e-04 - accuracy: 1.0000 - val_loss: 4.0449 - val_accuracy: 0.4978\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 3.3100e-04 - accuracy: 1.0000 - val_loss: 4.3386 - val_accuracy: 0.4984\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 1.8432e-04 - accuracy: 1.0000 - val_loss: 4.5694 - val_accuracy: 0.4981\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f64b9f6db00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "563RVFZaYYl_",
        "colab_type": "code",
        "outputId": "146f0125-bf31-43b6-e220-c786d90adec4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "e = model.layers[0]\n",
        "weights = e.get_weights()[0]\n",
        "print(weights.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9-rUWj6ZXSP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "for word_num in range(1, vocab_size):\n",
        "\tword = reverse_word_index[word_num]\n",
        "\tembeddings = weights[word_num]\n",
        "\tout_m.write(word + \"\\n\")\n",
        "\tout_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
        "\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVl3CRA8g13b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  pass\n",
        "else:\n",
        "  files.download('vecs.tsv')\n",
        "  files.download('meta.tsv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NnZeNrHiHjx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}